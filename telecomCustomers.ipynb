{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Telecom customers - churn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# EDA\n",
    "import pandas as pd\n",
    "from ydata_profiling import ProfileReport\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# model\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, precision_recall_curve, auc\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import optuna\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "import shap\n",
    "import joblib\n",
    "\n",
    "# Make sure this points to the correct directory\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), 'src')))\n",
    "\n",
    "# my packeges\n",
    "from src.data_download import download_and_extract_kaggle_dataset\n",
    "from src.preprocessing import target_variable_distribution, encode_binary_columns, encode_non_binary_columns,check_column_numeric,clean_column_names\n",
    "\n",
    "# ignoring warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data download from Kaggle\n",
    "\n",
    "I created function which downloads a Kaggle dataset as a zip file into the specified folder (dataset) and extracts it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "data_name = 'tarekmuhammed/telecom-customers'\n",
    "data_path = 'dataset'\n",
    "\n",
    "# download dataset from kaggle \n",
    "download_and_extract_kaggle_dataset(data_name, data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory data analysis (EDA)\n",
    " For EDA I use ProfileEReport, which generates and interactive, detailed report for an entire dataset with minimal code. It automatically performs a comprehensive Exploratory Data Analysis (EDA) and provides an overview of the data, helping you identify patterns, anomalies, and key statistics for further analysis. The report includes various insights such as missing values, distributions, correlations, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset \n",
    "df = pd.read_csv(\"./dataset/Telecom Customers Churn.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the profile report\n",
    "profile = ProfileReport(df, title=\"EDA\", explorative=True)\n",
    "\n",
    "# Display the report in a notebook \n",
    "profile.to_notebook_iframe()\n",
    "\n",
    "# Save the report to an HTML file\n",
    "profile.to_file(\"EDA_TEL.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Overview:\n",
    "\n",
    " - Number of variables (columns): 21\n",
    " - Number of observations (rows): 7043\n",
    " - Missing cells: There are no missing values, which is beneficial for data quality.\n",
    " - Duplicate rows: No duplicate rows, ensuring data integrity.\n",
    "\n",
    " Suggestions:\n",
    " - Feature Encoding: Most variables will need encoding (e.g., categorical to numeric) for model training.\n",
    " - Feature engineering: create new variables which could help the model make better predictions e.g StreamingService, ContractMonth, LongTermCustomer\n",
    " - Key Predictors for Churn: Based on the correlation matrix, features like Contract, TechSupport, tenure, and OnlineSecurity appear to be important predictors of churn.\n",
    " - Feature Redundancy: \n",
    "      - combine StreamingMovies and StreamingTV into a single feature (e.g., \"StreamingService\") \n",
    "      - drop PhoneService in favor of MultipleLines, which captures phone service status\n",
    "      - change TotalCharges datatype from object to numeric "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Type Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check column TotalCharge\n",
    "print('The column TotalCharges has missing values, likely because the tenure is 0. We will fill these missing values with 0.')\n",
    "check_column_numeric(df,'TotalCharges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'TotalCharges' to numeric if it's an object or has non-numeric characters\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "\n",
    "# fill 'TotalCharges' with 0 where 'tenure' is 0 and 'TotalCharges' is NaN\n",
    "df.loc[(df['tenure'] == 0) & (df['TotalCharges'].isna()), 'TotalCharges'] = 0\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new variables\n",
    "df['StreamingService'] = np.where((df['StreamingTV'] == 'Yes') | (df['StreamingMovies'] == 'Yes'), 'Yes', 'No')\n",
    "#df['AverageChargePerMonth'] = df['TotalCharges'] / (df['tenure'] + 1)\n",
    "df['ContractMonth'] = df['tenure'] % 12\n",
    "df['LongTermCustomer'] = np.where(df['tenure'] > 12, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = encode_non_binary_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = encode_binary_columns(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name conventions for columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean column names\n",
    "df = clean_column_names(df)\n",
    "\n",
    "# Move 'Churn' to the first column\n",
    "cols = ['churn'] + [col for col in df.columns if col != 'churn']\n",
    "\n",
    "# Reorder the columns of the DataFrame\n",
    "df = df[cols]\n",
    "\n",
    "# Display the column names to check the order\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Removing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove features with low variance\n",
    "selector = VarianceThreshold(threshold=0.01)\n",
    "X_new = selector.fit_transform(X)\n",
    "\n",
    "# Drop highly correlated features\n",
    "correlation_matrix = X.corr()\n",
    "highly_correlated_features = set()\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.90:  # Threshold for correlation\n",
    "            colname = correlation_matrix.columns[i]\n",
    "            highly_correlated_features.add(colname)\n",
    "\n",
    "X = X.drop(labels=highly_correlated_features, axis=1)\n",
    "print(highly_correlated_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecassary features \n",
    "customer_ids = df['customerID']\n",
    "columns_to_drop = ['customerID','PhoneService', 'StreamingTV', 'StreamingMovies' ]\n",
    "\n",
    "df = df.drop(columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building, Evaluation, Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target distribution\n",
    "target_variable_distribution(df, target_col=\"churn\")\n",
    "print('The dataset has a clear imbalance between customers who did not churn (73.46%) and those who did churn (26.54%).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing sets\n",
    "X = df.drop('churn', axis=1)\n",
    "y = df['churn']  \n",
    "\n",
    "# using parameter stratify especially when the dataset is imbalanced\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking model\n",
    "\n",
    "- Concept: Stacking involves training multiple base models (e.g., CatBoost, XGBoost) and then using their predictions as inputs for a higher-level model (meta-model) like Logistic Regression.\n",
    "- Goal: The meta-model combines the base models' predictions to improve overall performance.\n",
    "- Strength: It leverages the strengths of different algorithms, often outperforming individual models by capturing diverse patterns in the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal classification threshold: 0.349689581413797\n",
    "Classification Report (After Threshold Tuning):\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.89      0.75      0.81      1035\n",
    "           1       0.52      0.73      0.60       374\n",
    "\n",
    "    accuracy                           0.75      1409\n",
    "   macro avg       0.70      0.74      0.71      1409\n",
    "weighted avg       0.79      0.75      0.76      1409\n",
    "\n",
    "Confusion Matrix:\n",
    "[[779 256]\n",
    " [101 273]]\n",
    "ROC AUC Score: 0.8213916660208221\n",
    "True Negatives: 779, False Positives: 256, False Negatives: 101, True Positives: 273\n",
    "\n",
    "Conclusion:\n",
    "- The model shows solid overall performance but can be improved in predicting the positive class (class 1). The lower precision for class 1 suggests that there are many false positives, and the lower F1-score for class 1 indicates a potential trade-off between precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set up logging for better debugging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(columns=['churn'])  # Replace 'churn' with your actual target column\n",
    "y = df['churn']\n",
    "\n",
    "# Train-test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Handle class imbalance using SMOTE (Synthetic Minority Over-sampling Technique)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define Optuna objective for CatBoost tuning\n",
    "def catboost_objective(trial):\n",
    "    param = {\n",
    "        'depth': trial.suggest_int('depth', 4, 10),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 0.3),\n",
    "        'iterations': trial.suggest_int('iterations', 100, 1000),\n",
    "        'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),\n",
    "        'border_count': trial.suggest_int('border_count', 5, 255),\n",
    "        'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1, 10),\n",
    "        'eval_metric': 'AUC',\n",
    "        'random_seed': 42,\n",
    "        'verbose': 0\n",
    "    }\n",
    "\n",
    "    catboost_model = CatBoostClassifier(**param)\n",
    "    score = cross_val_score(catboost_model, X_train_resampled, y_train_resampled, scoring='roc_auc', cv=5).mean()\n",
    "    return score\n",
    "\n",
    "# Define Optuna objective for XGBoost tuning\n",
    "def xgboost_objective(trial):\n",
    "    param = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 4, 10),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-4, 0.3),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 10),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 10),\n",
    "        'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1, 10),\n",
    "        'use_label_encoder': False,\n",
    "        'eval_metric': 'auc',\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "    xgb_model = XGBClassifier(**param)\n",
    "    score = cross_val_score(xgb_model, X_train_resampled, y_train_resampled, scoring='roc_auc', cv=5).mean()\n",
    "    return score\n",
    "\n",
    "# Run Optuna for CatBoost\n",
    "catboost_study = optuna.create_study(direction='maximize')\n",
    "catboost_study.optimize(catboost_objective, n_trials=50)\n",
    "catboost_best_params = catboost_study.best_params\n",
    "\n",
    "# Run Optuna for XGBoost\n",
    "xgboost_study = optuna.create_study(direction='maximize')\n",
    "xgboost_study.optimize(xgboost_objective, n_trials=50)\n",
    "xgboost_best_params = xgboost_study.best_params\n",
    "\n",
    "# Stacking model with CatBoost and XGBoost\n",
    "catboost_model = CatBoostClassifier(**catboost_best_params)\n",
    "xgboost_model = XGBClassifier(**xgboost_best_params)\n",
    "\n",
    "estimators = [\n",
    "    ('catboost', catboost_model),\n",
    "    ('xgboost', xgboost_model)\n",
    "]\n",
    "\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=CatBoostClassifier(verbose=0),  # or XGBoostClassifier\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# Fit the stacking model on resampled data\n",
    "stacking_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict probabilities and labels on the test set\n",
    "y_pred_proba = stacking_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Tune the classification threshold based on precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "optimal_idx = np.argmax(f1_scores)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "print(f\"Optimal classification threshold: {optimal_threshold}\")\n",
    "\n",
    "# Apply the tuned threshold to make predictions\n",
    "y_pred_threshold_tuned = (y_pred_proba >= optimal_threshold).astype(int)\n",
    "\n",
    "# Classification report after threshold tuning\n",
    "print(\"Classification Report (After Threshold Tuning):\")\n",
    "print(classification_report(y_test, y_pred_threshold_tuned))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_threshold_tuned)\n",
    "print(f\"Confusion Matrix:\\n{cm}\")\n",
    "\n",
    "# ROC AUC score\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"ROC AUC Score: {roc_auc}\")\n",
    "\n",
    "# Detailed confusion matrix breakdown\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"True Negatives: {tn}, False Positives: {fp}, False Negatives: {fn}, True Positives: {tp}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Changes:\n",
    "1. ADASYN Resampling: I replaced SMOTE with ADASYN to help in generating synthetic samples based on the difficulty of learning.\n",
    "2. GridSearchCV: This is used to find the best hyperparameters, optimizing them over a range of values.\n",
    "3. F1 Score for Threshold Selection: The optimal threshold is selected by maximizing the F1 score instead of a simple recall-precision trade-off.\n",
    "\n",
    "- These steps will help balance the precision and recall, and potentially improve the performance on the imbalanced churn dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Hyperparameters: {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 1000, 'scale_pos_weight': 1, 'subsample': 0.8}\n",
    "Optimal classification threshold: 0.26446035504341125\n",
    "Confusion Matrix:\n",
    " [[747 288]\n",
    " [ 75 299]]\n",
    "Classification Report (After Threshold Tuning):\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.91      0.72      0.80      1035\n",
    "           1       0.51      0.80      0.62       374\n",
    "\n",
    "    accuracy                           0.74      1409\n",
    "   macro avg       0.71      0.76      0.71      1409\n",
    "weighted avg       0.80      0.74      0.76      1409\n",
    "\n",
    "ROC AUC Score: 0.83291999276654\n",
    "\n",
    "Conclusion:\n",
    "\n",
    "This updated model demonstrates a better balance between precision and recall, especially in identifying churn cases. The recall for churn improved from 0.73 to 0.80, and the ROC AUC score also increased from 0.8214 to 0.8329. While there was a small trade-off in terms of precision for the churn class, the overall performance of the model improved, making it more effective in detecting churn.\n",
    "\n",
    "Next Steps:\n",
    "\n",
    "Further Threshold Tuning: I can experiment with additional threshold adjustments to maintain the higher recall while improving precision. This will help to fine-tune the model's prediction performance.\n",
    "Cross-Validation: I plan to continue evaluating the model using cross-validation to ensure that the improvements generalize well across the entire dataset and are not limited to the test set.\n",
    "Feature Importance/Analysis: I can investigate which features are contributing the most to these improvements. This will help to determine whether further feature engineering can push the model's performance even further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Resample using ADASYN (alternative to SMOTE)\n",
    "adasyn = ADASYN(random_state=42)\n",
    "X_train_resampled, y_train_resampled = adasyn.fit_resample(X_train, y_train)\n",
    "\n",
    "# Hyperparameter tuning with grid search for threshold optimization\n",
    "param_grid = {\n",
    "    'max_depth': [5, 6, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'n_estimators': [200, 500, 1000],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'scale_pos_weight': [1, 3, 10]\n",
    "}\n",
    "\n",
    "# Use grid search for better hyperparameter selection\n",
    "grid_search = GridSearchCV(XGBClassifier(use_label_encoder=False), param_grid, scoring='roc_auc', cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Best hyperparameters found by grid search\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Train the optimized XGBoost model\n",
    "xgb_model = XGBClassifier(**best_params, use_label_encoder=False)\n",
    "xgb_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict probabilities for threshold tuning\n",
    "y_pred_proba_train = xgb_model.predict_proba(X_train)[:, 1]\n",
    "y_pred_proba_test = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Fine-tune classification threshold using precision-recall tradeoff\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba_test)\n",
    "pr_auc = auc(recall, precision)\n",
    "\n",
    "# Plot Precision-Recall curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, marker='.')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Threshold selection: optimal threshold based on F1 score\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "optimal_idx = np.argmax(f1_scores)  # F1 score maximization\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "print(f'Optimal classification threshold: {optimal_threshold}')\n",
    "\n",
    "# Predict with the fine-tuned threshold\n",
    "y_pred_adjusted = (y_pred_proba_test >= optimal_threshold).astype(int)\n",
    "\n",
    "# Confusion matrix and evaluation metrics\n",
    "cm = confusion_matrix(y_test, y_pred_adjusted)\n",
    "print(f\"Confusion Matrix:\\n {cm}\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report (After Threshold Tuning):\")\n",
    "print(classification_report(y_test, y_pred_adjusted))\n",
    "\n",
    "# ROC AUC Score\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba_test)\n",
    "print(f\"ROC AUC Score: {roc_auc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a file\n",
    "joblib.dump(xgb_model, 'xgb_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross - validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-Validation AUC Scores: [0.83459357 0.82601223 0.83685958 0.84436245 0.84650973]\n",
    "Mean Cross-Validation AUC Score: 0.8376675120035433\n",
    "Optimal classification threshold: 0.26446035504341125\n",
    "\n",
    "Conclusion:\n",
    "\n",
    "The model's cross-validation AUC scores demonstrate its strong discriminative ability, with a mean score of 0.84. The optimal classification threshold of 0.2645 is a crucial value for making predictions, and adjusting this threshold further can help fine-tune the balance between precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import precision_recall_curve, auc, roc_auc_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the saved model\n",
    "xgb_model = joblib.load(\"xgb_model.pkl\")\n",
    "\n",
    "# Set up 5-fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Cross-validation to evaluate model performance\n",
    "cv_scores = cross_val_score(xgb_model, X_train, y_train, cv=cv, scoring='roc_auc')\n",
    "print(f'Cross-Validation AUC Scores: {cv_scores}')\n",
    "print(f'Mean Cross-Validation AUC Score: {np.mean(cv_scores)}')\n",
    "\n",
    "# Predict probabilities for the test set (after cross-validation)\n",
    "y_pred_proba_test = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Fine-tune classification threshold using precision-recall tradeoff\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba_test)\n",
    "pr_auc = auc(recall, precision)\n",
    "\n",
    "# Plot Precision-Recall curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, marker='.')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Threshold selection: optimal threshold based on F1 score\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "optimal_idx = np.argmax(f1_scores)  # F1 score maximization\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "print(f'Optimal classification threshold: {optimal_threshold}')\n",
    "\n",
    "# Predict with the fine-tuned threshold\n",
    "y_pred_adjusted = (y_pred_proba_test >= optimal_threshold).astype(int)\n",
    "\n",
    "# Confusion matrix and evaluation metrics\n",
    "cm = confusion_matrix(y_test, y_pred_adjusted)\n",
    "print(f\"Confusion Matrix:\\n {cm}\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report (After Threshold Tuning):\")\n",
    "print(classification_report(y_test, y_pred_adjusted))\n",
    "\n",
    "# ROC AUC Score\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba_test)\n",
    "print(f\"ROC AUC Score: {roc_auc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Ideas at the End\n",
    "\n",
    " - Cost-sensitive learning: Incorporate techniques that weigh the cost of misclassification differently for each class, helping to minimize costly false positives or negatives.\n",
    " - Gradient Boosting with Early Stopping: Prevent overfitting and improve generalization, especially for complex models.\n",
    " - Feature engineering: Explore creating new features from existing ones to provide the model with more meaningful data\n",
    " - Threshold tuning: Continue experimenting with different thresholds for classification to balance precision and recall based on business priorities.\n",
    " ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
